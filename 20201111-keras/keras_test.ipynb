{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.8 64-bit ('tfx': conda)",
   "display_name": "Python 3.7.8 64-bit ('tfx': conda)",
   "metadata": {
    "interpreter": {
     "hash": "44f61f1a971a06a22aab637a590d68cc38d998c4e258324efd9cbb5d9ca43d21"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Copying gs://pjm-pipeline-train/OL653374/20200916/OL653374_FM2_BS20200916205228.model_training.bin.tfrecord.gz...\n",
      "\n",
      "Operation completed over 1 objects/164.2 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "! gsutil cp gs://pjm-pipeline-train/OL653374/20200916/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "OL653374_FM2_BS20200916205228.model_training.bin.tfrecord.gz\n"
     ]
    }
   ],
   "source": [
    "! ls | grep tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseConstructorLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    This layer takes a (batch of) 1d variable-length tensor of indices\n",
    "    and returns a 2d sparse tensor in which every named index has value 1, \n",
    "    0 otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        super(SparseConstructorLayer, self).__init__()\n",
    "        \n",
    "\n",
    "    def call(self, inputs):\n",
    "        row_inds = inputs.indices[:,0]\n",
    "        col_inds = tf.cast(inputs.values, tf.int64)\n",
    "        \n",
    "        indices = tf.transpose(tf.stack([row_inds, col_inds]))\n",
    "        values = tf.ones(tf.shape(inputs.values))\n",
    "        dense_shape = [tf.shape(inputs)[0], tf.cast(self.n, tf.int64)]\n",
    "        \n",
    "        return tf.SparseTensor(indices=indices, values=values, dense_shape=dense_shape)\n",
    "        \n",
    "\n",
    "    def get_config(self):\n",
    "        return {'n': self.n}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_SPEC = {'indices': tf.io.VarLenFeature(tf.int64),\n",
    "                'values': tf.io.VarLenFeature(tf.float32),\n",
    "                'label': tf.io.FixedLenFeature([], tf.int64, default_value=0)}\n",
    "\n",
    "def _gzip_reader_fn(filenames):\n",
    "  \"\"\"Small utility returning a record reader that can read gzip'ed files.\"\"\"\n",
    "  return tf.data.TFRecordDataset(\n",
    "      filenames,\n",
    "      compression_type='GZIP')\n",
    "      \n",
    "tfde = tf.data.experimental.make_batched_features_dataset(file_pattern='OL653374_FM2_BS20200916205228.model_training.bin.tfrecord.gz',\n",
    "                                                         batch_size=1024,\n",
    "                                                         features=FEATURE_SPEC,\n",
    "                                                         reader=_gzip_reader_fn,\n",
    "                                                         label_key='label')\n",
    "# tfde = tfde.map(lambda x: {'label':x['label'],'indices':x['indices']})                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "({'indices': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f5634100210>, 'values': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f55d0728e50>}, <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([0, 0, 0, ..., 1, 0, 0])>)\n({'indices': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f56340ffc10>, 'values': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f55d0738550>}, <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([0, 0, 0, ..., 0, 0, 0])>)\n({'indices': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f55d0728c10>, 'values': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f55d0728150>}, <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([0, 0, 0, ..., 0, 0, 1])>)\n"
     ]
    }
   ],
   "source": [
    "for i in tfde.take(3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "indices (InputLayer)         [(1024, 50010000)]        0         \n",
      "_________________________________________________________________\n",
      "sparse_constructor_layer (Sp (None, 50010000)          0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 50010001  \n",
      "=================================================================\n",
      "Total params: 50,010,001\n",
      "Trainable params: 50,010,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 4s 179ms/step - loss: 1.6373 - auc: 0.5118\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 4s 179ms/step - loss: 0.6332 - auc: 0.6312\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 4s 178ms/step - loss: 0.3645 - auc: 0.7436\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 4s 179ms/step - loss: 0.2947 - auc: 0.7867\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 4s 182ms/step - loss: 0.2738 - auc: 0.8024\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 4s 181ms/step - loss: 0.3080 - auc: 0.7925\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 4s 184ms/step - loss: 0.2947 - auc: 0.8060\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 4s 183ms/step - loss: 0.6500 - auc: 0.6803\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 4s 177ms/step - loss: 0.4824 - auc: 0.6960\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 4s 180ms/step - loss: 0.3813 - auc: 0.7526\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Normally we'd use tft.create_and_apply_vocabulary to convert the inputs\n",
    "from a very sparse 50MM-dimensional space down to something more tractable \n",
    "like 40,000. As is, if we don't transform it still works.\n",
    "\"\"\"\n",
    "MAX_IDX=int(50.01e6)\n",
    "\n",
    "input_layer = tf.keras.layers.Input(int(50.01e6), batch_size=1024, sparse=True, name='indices')\n",
    "\n",
    "sparsed_input = SparseConstructorLayer(MAX_IDX)(input_layer)\n",
    "\n",
    "lin_fn = tf.keras.layers.Dense(1, \n",
    "               activation='sigmoid', \n",
    "            #    kernel_regularizer=tf.keras.regularizers.l2() # 0.001\n",
    "                              )(sparsed_input)\n",
    "\n",
    "reg_model = tf.keras.Model(inputs = input_layer,\n",
    "                           outputs = lin_fn)\n",
    "\n",
    "reg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1), \n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[tf.keras.metrics.AUC()])\n",
    "reg_model.summary()    \n",
    "\n",
    "history = reg_model.fit(tfde, epochs=10, steps_per_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}